{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install gdown\n",
    "! pip install pandas\n",
    "! pip install seaborn\n",
    "! pip install numpy\n",
    "! pip install matplotlib\n",
    "! pip install scikit-learn\n",
    "! pip install pathlib\n",
    "\n",
    "\n",
    "import gdown\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pathlib import Path\n",
    "\n",
    "def download_from_gdrive(url, filename):\n",
    "    # Extract the file ID from the URL\n",
    "    file_id = url.split('/')[-2]\n",
    "    download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "    # Download the file\n",
    "    if Path(filename).exists():\n",
    "        print(f\"File '{filename}' already exists. Skipping download.\")\n",
    "    else:\n",
    "        gdown.download(download_url, filename, quiet=False)\n",
    "        print(f\"File downloaded as: {filename}\")\n",
    "\n",
    "train = 'https://drive.google.com/file/d/1guqSpDv1Q7ZZjSbXMYGbrTvGns0VCyU5/view?usp=drive_link'\n",
    "valid = 'https://drive.google.com/file/d/1j7x8xhMimKbvW62D-XeDfuRyj9ia636q/view?usp=drive_link'\n",
    "# Example usage\n",
    "\n",
    "download_from_gdrive(train, 'train.csv')\n",
    "download_from_gdrive(valid, 'valid.csv')\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "MAX_DEPTH = 20\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def manipulate_data(df):\n",
    "    df2 = df.copy()\n",
    "\n",
    "    # column_nunique = df.nunique()\n",
    "    # print(column_nunique)\n",
    "\n",
    "    df2['UsageBand'] = df2['UsageBand'].astype('category')\n",
    "    df2 = pd.get_dummies(df2, columns=['UsageBand'], prefix='UsageBand')\n",
    "    \n",
    "    # handle dates in processing\n",
    "    df2['Saledate'] = pd.to_datetime(df.saledate)\n",
    "    df2 = df2.select_dtypes(['number', 'datetime','bool'])  # drop all categorical variables\n",
    "\n",
    "    #df2 = df2.dropna()  # drop all rows with missing values\n",
    "    #df2 = df2[df2['YearMade'] >= 1900]  # remove outliers\n",
    "    #df2 = df2.drop_duplicates()  # drop duplicates\n",
    "\n",
    "    # Feature engineering with dates\n",
    "    df2['Age'] = df2['Saledate'].dt.year - df2['YearMade']\n",
    "    df2['SaleYear'] =  df2['Saledate'].dt.year\n",
    "    df2['SaleMonth'] =  df2['Saledate'].dt.month\n",
    "    # machineid is a unique identifier, so we drop it\n",
    "    # sale date is redundant, so we drop it\n",
    "    # modelid is a unique identifier, so we drop it\n",
    "    df2 = df2.drop(columns=['Saledate'])\n",
    "    df2 = df2.drop(columns=['MachineID'])\n",
    "    # df2 = df2.drop(columns=['ModelID'])  # don't touch this one !     \n",
    "  \n",
    "    #df2 = df2.set_index('SalesID')  # set the index to the unique identifier\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All the functions below are for the purpose of training a model\n",
    "# Compute permutation feature importance\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def important_features_analysis(model, X_test, y_test):\n",
    "    result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1)    \n",
    "\n",
    "    # Summarize feature importance    \n",
    "    feature_importances = pd.DataFrame(result.importances_mean, index=X_test.columns, columns=['Permutation Importance'])\n",
    "    feature_importances['Permutation Importance'] = feature_importances['Permutation Importance'] / feature_importances['Permutation Importance'].sum()\n",
    "    feature_importances['Feature importance'] = model.feature_importances_\n",
    "    feature_importances = feature_importances.sort_values(by='Permutation Importance', ascending=False)\n",
    "    print(feature_importances)\n",
    "\n",
    "    \n",
    "def train(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def RMSE(y_pred, y_true):\n",
    "    return ((y_pred - y_true) ** 2).mean() ** 0.5\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "def analyse_prediction(model , X_data, y_data , y_pred):\n",
    "    print(\"\\n\\nRMSE:\", round(RMSE(y_pred, y_data),3))\n",
    "    print(\"STD\", round(y_data.std(),3))\n",
    "    #important_features_analysis(model, X_data, y_data)\n",
    "\n",
    "    # sns.scatterplot(x=y_data, y=y_pred)\n",
    "    # xx = np.linspace(y_data.min(), y_data.max(), 100)\n",
    "\n",
    "    # plt.plot(xx, xx, 'r--')\n",
    "    # plt.xlabel('actual')\n",
    "    # plt.ylabel('predicted')\n",
    "\n",
    "\n",
    "def predict(model,X_data , y_data=None):\n",
    "    y_pred = model.predict(X_data)\n",
    "\n",
    "    if y_data is None:\n",
    "        return y_pred\n",
    "    \n",
    "    analyse_prediction(model, X_data , y_data , y_pred)    \n",
    "    return y_pred\n",
    "\n",
    "def summary(model,X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    y_train_pred = predict(model,X_train, y_train)\n",
    "    y_test_pred = predict(model,X_test, y_test)    \n",
    "   \n",
    "    return y_train_pred, y_test_pred\n",
    "\n",
    "\n",
    "def summary2(model,X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    y_train_pred, y_test_pred = summary(model, X_train, X_test, y_train, y_test)\n",
    "    return y_train_pred, y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN #########\n",
    "\n",
    "# Clean data\n",
    "df2 = manipulate_data(df)\n",
    "df2 = df2.set_index('SalesID')  # set the index to the unique identifier\n",
    "#df2 = df2.dropna()  # drop all rows with missing values\n",
    "\n",
    "\n",
    "# Remove outliers using 6 sigma method\n",
    "for col in df2.columns:    \n",
    "    mean = df2[col].mean()\n",
    "    std_dev = df2[col].std()    \n",
    "    lower_bound = mean - 3 * std_dev\n",
    "    upper_bound = mean + 3 * std_dev\n",
    "    df2 = df2[(df2[col] >= lower_bound) & (df2[col] <= upper_bound)]\n",
    "    #instead of dropna   \n",
    "    df2[col] = df2[col].fillna(mean)\n",
    "\n",
    "df2 = df2[df2['YearMade'] >= 1900]  # remove some outliers\n",
    "df2 = df2.drop_duplicates()  # drop duplicates\n",
    "# Prepare data for training\n",
    "X = df2.drop(columns='SalePrice')\n",
    "y = df2['SalePrice']\n",
    "print(\"Data shape:\", X.shape)\n",
    "\n",
    "\n",
    "#model = RandomForestRegressor(random_state=RANDOM_STATE, max_depth=MAX_DEPTH)\n",
    "model = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "X_small = X.sample(20000)\n",
    "y_small = y.loc[X_small.index]\n",
    "X_train, X_test, y_train, y_test = train(model, X_small, y_small)\n",
    "\n",
    "\n",
    "# Train model and summarize\n",
    "summary2(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_valid = pd.read_csv('valid.csv')\n",
    "#print(\"df -valid \" , df_valid.info())\n",
    "#df_index = df.drop(columns=['SalePrice']).columns\n",
    "#X_valid = df_valid[df_index]\n",
    "#X_valid = manipulate_data(df_valid)\n",
    "\n",
    "X_valid = pd.read_csv('valid.csv')\n",
    "X_valid = X_valid.set_index('SalesID')\n",
    "#print(X_valid.head())\n",
    "X_valid = manipulate_data(X_valid)\n",
    "print(X_valid.shape)\n",
    "# #he dumbest null handling possible - fill with mean value\n",
    "# for col in X_valid.columns:\n",
    "#     X_valid[col] = X_valid[col].fillna(X_valid[col].mean())\n",
    "\n",
    "y_valid_pred = predict(model, X_valid)\n",
    "#y_valid_pred = pd.Series(y_valid_pred, index=X_valid.index, name='SalePrice')\n",
    "y_valid_pred = pd.Series(y_valid_pred, index=X_valid.index, name='SalePrice')\n",
    "#y_valid_pred.info()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "f'submission_{datetime.now().isoformat()}'\n",
    "y_valid_pred.to_csv(f'submission_{datetime.now().isoformat()}.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
